{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "044cf5d0",
   "metadata": {},
   "source": [
    "# Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785096df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:17:10.427003Z",
     "start_time": "2024-08-02T19:17:09.462857Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from helper_functions import *\n",
    "from hk_news_features import *\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5a5183",
   "metadata": {},
   "source": [
    "# Plot settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2bf164b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:17:10.430590Z",
     "start_time": "2024-08-02T19:17:10.428182Z"
    }
   },
   "outputs": [],
   "source": [
    "MARKERSIZE=10\n",
    "FONT_SIZE = 18\n",
    "plt.rc('xtick', labelsize=FONT_SIZE)\n",
    "plt.rc('ytick', labelsize=FONT_SIZE)\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=FONT_SIZE)\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f458316",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb023b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:17:10.432698Z",
     "start_time": "2024-08-02T19:17:10.431443Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_DIR = f\"{os.getcwd()}/../\"\n",
    "MODEL_EVAL_DIR = BASE_DIR + \"model_eval/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec89b91a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:17:10.730470Z",
     "start_time": "2024-08-02T19:17:10.434030Z"
    }
   },
   "outputs": [],
   "source": [
    "fid_file = \"fid-finetune_data-dataset_hk-news-timeInterval_1-timeIntervalType_time-finetuneType_base.csv\"\n",
    "fid = pd.read_csv(MODEL_EVAL_DIR + fid_file)\n",
    "\n",
    "fid = set_type_of_time_cols(fid)\n",
    "\n",
    "for metric in METRICS:\n",
    "    for tactic in TACTICS:\n",
    "        fid[f'delta-target_{metric}_{tactic}'] = fid[f'target_{metric}_{tactic}'] - fid[f'curr_{metric}']\n",
    "\n",
    "    for test_set in HK_NEWS_TEST_SETS:\n",
    "        key = f\"{test_set}_{metric}\"\n",
    "        fid[f\"delta-target_{key}\"] = fid[f\"target_{key}\"] - fid[f\"curr_{key}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a411569e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:17:11.369285Z",
     "start_time": "2024-08-02T19:17:10.736856Z"
    }
   },
   "outputs": [],
   "source": [
    "general_fid_file = \"general_fid-finetune_data-dataset_hk-news-timeInterval_1-timeIntervalType_time-finetuneType_base.csv\"\n",
    "general_fid = pd.read_csv(MODEL_EVAL_DIR + general_fid_file)\n",
    "\n",
    "general_fid = set_type_of_time_cols(general_fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9de7f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T20:06:29.974837Z",
     "start_time": "2024-08-02T20:06:29.935445Z"
    }
   },
   "outputs": [],
   "source": [
    "general_fid[\n",
    "    ['test-set', 'curr_finetune', 'prev_finetune'] + BASIC_FEATURES + GENERIC_SYS_PERF_FEATURES\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c91f325",
   "metadata": {},
   "source": [
    "# Experimental settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b85e2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:17:11.375118Z",
     "start_time": "2024-08-02T19:17:11.373464Z"
    }
   },
   "outputs": [],
   "source": [
    "FEATURE_SET = ['curr_finetune', 'prev_finetune'] + BASIC_FEATURES + GENERIC_SYS_PERF_FEATURES\n",
    "FIP_MODEL_TYPE = 'rf'\n",
    "\n",
    "NUM_SEEDS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a673e5",
   "metadata": {},
   "source": [
    "# Sampling strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "555defe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:17:11.377223Z",
     "start_time": "2024-08-02T19:17:11.375914Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "boxplot_res_dict = {}\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f426afb7",
   "metadata": {},
   "source": [
    "## Uniform random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e615e67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:17:11.382045Z",
     "start_time": "2024-08-02T19:17:11.379066Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_random_sample(X, y, sample_size, sub_sample_type, seed=0):\n",
    "    if sample_size == 100:\n",
    "        return X, y, len(X.curr_finetune.unique())\n",
    "    \n",
    "    # seed np.random for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if 'finetunings' in sub_sample_type:\n",
    "        # select sample_size % finetunings to remove from the training set\n",
    "        finetunings = np.random.choice(\n",
    "            list(X.curr_finetune.unique()), \n",
    "            size=int((sample_size/100)*len(list(X.curr_finetune.unique()))), \n",
    "            replace=False\n",
    "        )\n",
    "    \n",
    "        x = X.loc[\n",
    "            (X.curr_finetune.isin(finetunings)) \n",
    "        ].copy()\n",
    "        \n",
    "        x = x.loc[\n",
    "            (x.prev_finetune.isin(finetunings)) \n",
    "        ]\n",
    "        \n",
    "        return x, y.loc[x.index], len(finetunings)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        # Create a random sample of the dataset with the specified sample size\n",
    "        indices = np.random.choice(\n",
    "            X.index, \n",
    "            size=int((sample_size/100)*len(X)), \n",
    "            replace=False\n",
    "        )\n",
    "\n",
    "        return X.loc[indices], y.loc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c47a8f95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:17:11.390076Z",
     "start_time": "2024-08-02T19:17:11.382833Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_uniform_random_sampling(\n",
    "    fid: pd.DataFrame,\n",
    "    target: str,\n",
    "    boxplot_res_dict: dict,\n",
    "    results: dict,\n",
    "    target_metric: str,\n",
    "    sample_sizes: list,\n",
    "    sub_sample_types: list = ['finetunings', 'features'],\n",
    "    feature_set: list = FEATURE_SET,\n",
    "    num_seeds: int = NUM_SEEDS,\n",
    "):\n",
    "\n",
    "    if 'test_set' in target:\n",
    "        fip_type = 'generic'\n",
    "        test_set = 'all-test-sets'\n",
    "    else:\n",
    "        fip_type = 'specific'\n",
    "        test_set = target.split(\"_\")[1]\n",
    "    \n",
    "    print(fid.columns)\n",
    "    train_split, val_split, test_split = get_hkNews_splits(\n",
    "        fid,\n",
    "        fixed_test_set=True,\n",
    "    )\n",
    "\n",
    "    x_train = train_split\n",
    "    y_train = train_split[target]\n",
    "    x_val = val_split\n",
    "    y_val = val_split[target]\n",
    "    x_test = test_split\n",
    "    y_test = test_split[target]\n",
    "    \n",
    "    print(f\"total num finetunings={len(x_train.curr_finetune.unique())}\")\n",
    "    \n",
    "    counter = len(results)\n",
    "    for sub_sample_type in sub_sample_types:\n",
    "        print(f\"[D] Sampling by {sub_sample_type}\")\n",
    "        for sample_size in sample_sizes:\n",
    "            print(f\"[D]\\tsample-size={sample_size}\")\n",
    "            mapes = []\n",
    "            maes = []\n",
    "            r2s = []\n",
    "            pccs = []\n",
    "            sccs = []\n",
    "            train_sizes = []\n",
    "            total_finetunings = []\n",
    "            for seed in range(num_seeds):  # Repeat multiple times for reliability\n",
    "                print(f\"[D]\\t\\tseed: {seed}\", end=\"\\r\", flush=True)\n",
    "                X_sample, y_sample, num_finetunings = create_random_sample(\n",
    "                    x_train, y_train, sample_size, sub_sample_type, seed\n",
    "                )\n",
    "\n",
    "                if X_sample.empty:\n",
    "                    continue\n",
    "                # Train the model on the sampled data\n",
    "                clf = RandomForestRegressor(random_state=1, n_estimators=100, max_depth=10)\n",
    "                clf.fit(X_sample[feature_set], y_sample)\n",
    "\n",
    "                # Evaluate the model on the test set\n",
    "                y_pred = clf.predict(x_test[feature_set])\n",
    "                mape, mae, r2, pcc, scc = compute_metrics(\n",
    "                    ground_truth=y_test,\n",
    "                    preds=y_pred,\n",
    "                    verbose=False,\n",
    "                )\n",
    "\n",
    "                mapes.append(mape)\n",
    "                maes.append(mae)\n",
    "                r2s.append(r2)\n",
    "                pccs.append(round(pcc*100, 3))\n",
    "                sccs.append(round(scc*100, 3))\n",
    "                train_sizes.append(len(X_sample))\n",
    "                total_finetunings.append(num_finetunings)\n",
    "\n",
    "                boxplot_res_dict[len(results)*num_seeds + seed] = {\n",
    "                    'seed': seed,\n",
    "                    'sampling': 'uniform',\n",
    "                    'fip_type': fip_type,\n",
    "                    'test-set': test_set,\n",
    "                    'sub_sample_type': sub_sample_type,\n",
    "                    'sample_size': sample_size,\n",
    "                    'num_finetunings': num_finetunings,\n",
    "                    'target': target,\n",
    "                    'target_metric': target_metric,\n",
    "                    'train_size': len(X_sample),\n",
    "                    'test_size': len(x_test),\n",
    "                    'mape': mape,\n",
    "                    'mae': mae,\n",
    "                    'pcc': round(pcc*100, 5),                \n",
    "                    'scc': round(scc*100, 5)\n",
    "                }\n",
    "\n",
    "            if len(pccs) == 0:\n",
    "                continue \n",
    "            print(f\"train_sizes={train_sizes}\")\n",
    "            results[counter] = {\n",
    "                'sampling': 'uniform',\n",
    "                'fip_type': fip_type,\n",
    "                'test-set': test_set,\n",
    "                'sub_sample_type': sub_sample_type,\n",
    "                'sample_size': sample_size,\n",
    "                'total_finetunings': np.mean(total_finetunings),\n",
    "                'target': target,\n",
    "                'target_metric': target_metric,\n",
    "                'avg-train_size': np.mean(train_sizes),\n",
    "                'std-train_size': np.std(train_sizes),\n",
    "                'test_size': len(x_test),\n",
    "            }\n",
    "\n",
    "            for metric_name, metric in zip(['mape', 'mae', 'r2', 'pcc', 'scc'], [mapes, maes, r2s, pccs, sccs]):\n",
    "                results[counter][f'avg-{metric_name}'] = np.mean(metric)\n",
    "                results[counter][f'stdev-{metric_name}'] = np.std(metric)\n",
    "                results[counter][f'90th-{metric_name}'] = np.percentile(metric, 90)\n",
    "                results[counter][f'99th-{metric_name}'] = np.percentile(metric, 99)\n",
    "\n",
    "\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72991065",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:40:22.439305Z",
     "start_time": "2024-08-02T19:34:30.654692Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the sample sizes you want to test\n",
    "# these are percentages of the train-set\n",
    "sample_sizes = [0.1, 1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "for metric in ['comet22']: #, 'chrf', 'comet22-qe', 'sacrebleu']:\n",
    "    for fip_type, fid in zip(['generic'], [general_fid]):\n",
    "        print(\"#\"*25 + f\" {metric.upper()} \" + \"#\"*25)\n",
    "        if 'specific' in fip_type:\n",
    "            for test_set in HK_NEWS_TEST_SETS:\n",
    "                FIP_FEATURE_SET = (\n",
    "                    SENT_OVERLAP_FEATURES[\"new_data\"] + EMBEDDING_FEATURES[\"new_data\"]\n",
    "                    + SENT_OVERLAP_FEATURES[\"finetune_data\"] + EMBEDDING_FEATURES[\"finetune_data\"]\n",
    "                )\n",
    "                target = f\"delta-target_{test_set}_{metric}\"\n",
    "                test_uniform_random_sampling(\n",
    "                    fid=fid,\n",
    "                    target=target,\n",
    "                    boxplot_res_dict=boxplot_res_dict,\n",
    "                    results=results,\n",
    "                    target_metric=metric,\n",
    "                    sample_sizes=sample_sizes,\n",
    "                    sub_sample_types=['finetunings'], #: list = ['features', 'finetunings'],\n",
    "                    feature_set = FIP_FEATURE_SET,\n",
    "                #     num_seeds: int = NUM_SEEDS,\n",
    "                )\n",
    "        else:\n",
    "            FIP_FEATURE_SET = BASIC_FEATURES + GENERIC_SYS_PERF_FEATURES #+ GENERIC_CONTENT_AWARE_FEATURES\n",
    "            target = f\"delta-target_test_set_{metric}\"\n",
    "            test_uniform_random_sampling(\n",
    "                fid=fid,\n",
    "                target=target,\n",
    "                boxplot_res_dict=boxplot_res_dict,\n",
    "                results=results,\n",
    "                target_metric=metric,\n",
    "                sample_sizes=sample_sizes,\n",
    "                sub_sample_types=['finetunings'], #: list = ['features', 'finetunings'],\n",
    "                feature_set = FIP_FEATURE_SET,\n",
    "            #     num_seeds: int = NUM_SEEDS,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de148a",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ea7730c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:41:58.382082Z",
     "start_time": "2024-08-02T19:41:58.370299Z"
    }
   },
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(results).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a4b45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:41:58.390893Z",
     "start_time": "2024-08-02T19:41:58.385639Z"
    }
   },
   "outputs": [],
   "source": [
    "list(res_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc4949b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:41:58.400678Z",
     "start_time": "2024-08-02T19:41:58.391981Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res_df[[\n",
    "    'target',\n",
    "    'fip_type',\n",
    "    'test-set',\n",
    "    'target_metric',\n",
    "    'sampling',\n",
    "    'sub_sample_type',\n",
    "    'sample_size',\n",
    "    'avg-train_size',\n",
    "    'std-train_size',\n",
    "    'test_size',\n",
    "    \n",
    "    'avg-mae',\n",
    "    'stdev-mae',\n",
    "    'avg-pcc',\n",
    "    'stdev-pcc',\n",
    "#     'avg-scc',\n",
    "#     'avg-r2',\n",
    "#     'avg-mape',\n",
    "    \n",
    "    '90th-mae',\n",
    "    '90th-pcc',\n",
    "#     '90th-scc',\n",
    "#     '90th-r2',\n",
    "#     '90th-mape',\n",
    "    \n",
    "#     '99th-mae',\n",
    "#     '99th-pcc',\n",
    "#     '99th-scc',\n",
    "#     '99th-r2',\n",
    "#     '99th-mape',\n",
    "]].loc[\n",
    "    (res_df.sub_sample_type == 'finetunings')\n",
    "    & (res_df.sample_size == 10)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba17c7a",
   "metadata": {},
   "source": [
    "### Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031aeb92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:42:40.958059Z",
     "start_time": "2024-08-02T19:42:40.241476Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "COLS = [\n",
    "    'avg-mae',\n",
    "    'avg-pcc',\n",
    "    '90th-mae',\n",
    "    '90th-pcc',\n",
    "]\n",
    "\n",
    "SAMPLE_SIZES = [\n",
    "    5, 10, 30, 50, 70, 90, 100\n",
    "#     5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100\n",
    "]\n",
    "\n",
    "for x_col in COLS:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    \n",
    "    plot_data = res_df.loc[\n",
    "        res_df.sample_size.isin(SAMPLE_SIZES)\n",
    "    ].copy()\n",
    "        \n",
    "    sns_plot = sns.barplot(\n",
    "        data=plot_data,\n",
    "        x='sample_size',\n",
    "        y=x_col,\n",
    "        hue='test-set',\n",
    "        ax=ax,\n",
    "#         hue_order=targets,\n",
    "        palette=sns.color_palette(\n",
    "            palette='gist_heat', \n",
    "            n_colors=len(plot_data['test-set'].unique())\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    if 'avg' in x_col:\n",
    "        \n",
    "        # Add error bars\n",
    "        num_hue_levels = len(plot_data.sub_sample_type.unique())\n",
    "        num_categories = len(plot_data.sample_size.unique())\n",
    "\n",
    "        for i, patch in enumerate(ax.patches):\n",
    "            # Determine the index of the category and hue\n",
    "            category_index = i // num_hue_levels\n",
    "            hue_index = i % num_hue_levels\n",
    "\n",
    "            # Calculate the center of each bar\n",
    "            bar_center = patch.get_x() + patch.get_width() / 2\n",
    "\n",
    "            # Get the corresponding error value\n",
    "            error = plot_data[f\"stdev-{x_col.split('-')[1]}\"].iloc[category_index * num_hue_levels + hue_index]\n",
    "\n",
    "            # Add error bars\n",
    "            ax.errorbar(\n",
    "                bar_center, \n",
    "                patch.get_height(), \n",
    "                yerr=error, \n",
    "                fmt='none', \n",
    "                c='black', \n",
    "                capsize=5\n",
    "            )\n",
    "\n",
    "    ax.set_ylabel(x_col.capitalize().replace(\"-\", \" \"))\n",
    "    ax.set_xlabel(\"Sample size\")\n",
    "#         ax.set_yscale('log')\n",
    "\n",
    "\n",
    "    ax.legend(\n",
    "        title='Sub-sample type',\n",
    "        frameon=False,\n",
    "    )\n",
    "    if 'pcc' in x_col:\n",
    "        ax.legend(\n",
    "            loc='upper left', \n",
    "            bbox_to_anchor=(.2, 1.35),\n",
    "            ncol=num_hue_levels,\n",
    "            title='Sub-sample type',\n",
    "            frameon=True,\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0792d088",
   "metadata": {},
   "source": [
    "### Box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d121c03d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:43:28.414851Z",
     "start_time": "2024-08-02T19:43:28.382524Z"
    }
   },
   "outputs": [],
   "source": [
    "boxplot_res = pd.DataFrame(boxplot_res_dict).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578e15f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T00:55:54.869753Z",
     "start_time": "2024-08-03T00:55:54.836867Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "boxplot_res.loc[\n",
    "    (boxplot_res.sample_size == 20)\n",
    "    & (boxplot_res.target_metric == 'comet22')\n",
    "    & (boxplot_res.fip_type == 'specific')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b4be7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T20:20:16.332775Z",
     "start_time": "2024-08-02T20:20:14.653056Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for metric in boxplot_res.target_metric.unique():\n",
    "    \n",
    "    plot_data = boxplot_res.loc[\n",
    "        (boxplot_res.target_metric == metric)\n",
    "    ].copy()\n",
    "    \n",
    "    for y_col in ['pcc', 'mape', 'scc']:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "        hue_col = 'fip_type' # 'test-set'  \n",
    "        sns.lineplot(\n",
    "            data=plot_data, \n",
    "            x=\"num_finetunings\",\n",
    "            y=y_col, \n",
    "            hue=hue_col,\n",
    "            ax=ax,\n",
    "            palette=sns.color_palette(\n",
    "                palette='gist_heat', \n",
    "                n_colors=len(plot_data[hue_col].unique())\n",
    "            ),\n",
    "#             legend=False,\n",
    "        )\n",
    "\n",
    "        # Create the second y-axis and plot\n",
    "        ax2 = ax.twinx()\n",
    "        sns.lineplot(\n",
    "            data=plot_data, \n",
    "            x=\"num_finetunings\",\n",
    "            y='mae', \n",
    "            hue=hue_col,\n",
    "            ax=ax2,\n",
    "            label=f'MAE-{plot_data[hue_col].unique()}',\n",
    "            palette=sns.color_palette(\n",
    "                palette='Paired', \n",
    "                n_colors=len(plot_data[hue_col].unique())\n",
    "            ),\n",
    "            legend=False,\n",
    "        )\n",
    "\n",
    "        ax.set_ylabel(y_col.upper())\n",
    "        ax2.set_ylabel(\"MAE\")\n",
    "        ax.set_xlabel(\"Number of finetunings\")\n",
    "\n",
    "#         ax.set_xscale('log')\n",
    "\n",
    "        # Custom legend\n",
    "        lines1, labels1 = ax.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        for line, label in zip(lines2, labels2):\n",
    "            line.set_linestyle(\"--\")  # Customize the line style for the second axis\n",
    "\n",
    "        # Combine legends and add hue information\n",
    "        combined_lines = lines1 + lines2\n",
    "        combined_labels = [f\"{label} (PCC)\" for label in labels1] + [f\"{label} (MAE)\" for label in labels1]\n",
    "\n",
    "        # Position the legend in the middle right\n",
    "        ax.legend(combined_lines, combined_labels, loc='center right')\n",
    "\n",
    "\n",
    "        ax.set_title(f\"{metric}\")\n",
    "        plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env-amt]",
   "language": "python",
   "name": "conda-env-env-amt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "247.43px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
