{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "044cf5d0",
   "metadata": {},
   "source": [
    "# Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785096df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:59:28.730442Z",
     "start_time": "2024-07-29T19:59:27.506968Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from helper_functions import *\n",
    "from opus_eng_fra_features import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2dc16f",
   "metadata": {},
   "source": [
    "# Plot settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dcf0f32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:59:28.736670Z",
     "start_time": "2024-07-29T19:59:28.731590Z"
    }
   },
   "outputs": [],
   "source": [
    "MARKERSIZE=10\n",
    "FONT_SIZE = 18\n",
    "plt.rc('xtick', labelsize=FONT_SIZE)\n",
    "plt.rc('ytick', labelsize=FONT_SIZE)\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=FONT_SIZE)\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f458316",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb023b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:59:28.738740Z",
     "start_time": "2024-07-29T19:59:28.737338Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_DIR = f\"{os.getcwd()}/../\"\n",
    "MODEL_EVAL_DIR = BASE_DIR + \"model_eval/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a411569e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:59:29.066005Z",
     "start_time": "2024-07-29T19:59:28.739950Z"
    }
   },
   "outputs": [],
   "source": [
    "general_fid_file = \"general_fid-finetune_data-dataset_opus_eng_fra-timeInterval_10000-timeIntervalType_sentence-finetuneType_base.csv\"\n",
    "general_fid = pd.read_csv(MODEL_EVAL_DIR + general_fid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9de7f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:59:29.069961Z",
     "start_time": "2024-07-29T19:59:29.066989Z"
    }
   },
   "outputs": [],
   "source": [
    "list(general_fid.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c91f325",
   "metadata": {},
   "source": [
    "# Experimental settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b85e2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:59:29.072491Z",
     "start_time": "2024-07-29T19:59:29.070698Z"
    }
   },
   "outputs": [],
   "source": [
    "FEATURE_SET = ['curr_finetune', 'prev_finetune'] + BASIC_FEATURES + GENERIC_SYS_PERF_FEATURES + GENERIC_CONTENT_AWARE_FEATURES\n",
    "FIP_FEATURE_SET = BASIC_FEATURES + GENERIC_SYS_PERF_FEATURES + GENERIC_CONTENT_AWARE_FEATURES\n",
    "TARGET_METRIC = 'comet22'\n",
    "FIP_MODEL_TYPE = 'rf'\n",
    "\n",
    "NUM_SEEDS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cc6f17",
   "metadata": {},
   "source": [
    "# Get original train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be987b8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:26:48.285736Z",
     "start_time": "2024-07-30T18:26:48.256815Z"
    }
   },
   "outputs": [],
   "source": [
    "general_fid[BASIC_FEATURES].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe630c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:59:29.090437Z",
     "start_time": "2024-07-29T19:59:29.073253Z"
    }
   },
   "outputs": [],
   "source": [
    "train_split, val_split, test_split = get_opusEngFra_splits(general_fid)\n",
    "\n",
    "target = f\"delta-target_test_set_{TARGET_METRIC}\"\n",
    "\n",
    "x_train = train_split[FEATURE_SET]\n",
    "y_train = train_split[target]\n",
    "x_val = val_split[FEATURE_SET]\n",
    "y_val = val_split[target]\n",
    "x_test = test_split[FEATURE_SET]\n",
    "y_test = test_split[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d50357c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T16:12:03.652719Z",
     "start_time": "2024-07-30T16:12:03.454607Z"
    }
   },
   "outputs": [],
   "source": [
    "train_split[BASIC_FEATURES + GENERIC_SYS_PERF_FEATURES + [target]].to_csv(\n",
    "    \"train-opus_eng_fra-generic_fip-basic_sys_perf_features.csv\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "test_split[BASIC_FEATURES + GENERIC_SYS_PERF_FEATURES + [target]].to_csv(\n",
    "    \"test-opus_eng_fra-generic_fip-basic_sys_perf_features.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8485da6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:59:29.095703Z",
     "start_time": "2024-07-29T19:59:29.092525Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a673e5",
   "metadata": {},
   "source": [
    "# Sampling strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "555defe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:59:29.098896Z",
     "start_time": "2024-07-29T19:59:29.096848Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "boxplot_res_dict = {}\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf2a7b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T19:59:29.114612Z",
     "start_time": "2024-07-29T19:59:29.103060Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f426afb7",
   "metadata": {},
   "source": [
    "## Uniform random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c47a8f95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:32:47.349292Z",
     "start_time": "2024-07-29T19:59:40.649049Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_random_sample(X, y, sample_size, sub_sample_type, seed=0):\n",
    "    if sample_size == 100:\n",
    "        return X, y\n",
    "    \n",
    "    # seed np.random for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if 'finetunings' in sub_sample_type:\n",
    "        # select sample_size % finetunings to remove from the training set\n",
    "        finetunings = np.random.choice(\n",
    "            list(X.curr_finetune.unique()), \n",
    "            size=int((sample_size/100)*len(list(X.curr_finetune.unique()))), \n",
    "            replace=False\n",
    "        )\n",
    "\n",
    "        x = X.loc[\n",
    "                (X.curr_finetune.isin(finetunings)) \n",
    "                | (X.prev_finetune.isin(finetunings)) \n",
    "            ]\n",
    "        return x, y.loc[x.index]\n",
    "            \n",
    "    else:\n",
    "        # Create a random sample of the dataset with the specified sample size\n",
    "        indices = np.random.choice(\n",
    "            X.index, \n",
    "            size=int((sample_size/100)*len(X)), \n",
    "            replace=False\n",
    "        )\n",
    "\n",
    "        return X.loc[indices], y.loc[indices]\n",
    "\n",
    "\n",
    "# Define the sample sizes you want to test\n",
    "# these are percentages of the train-set\n",
    "sample_sizes = [0.1, 1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "for sub_sample_type in ['finetunings', 'features']:\n",
    "    print(f\"[D] Sampling by {sub_sample_type}\")\n",
    "    for sample_size in sample_sizes:\n",
    "        print(f\"[D]\\tsample-size={sample_size}\")\n",
    "        mapes = []\n",
    "        maes = []\n",
    "        r2s = []\n",
    "        pccs = []\n",
    "        sccs = []\n",
    "        for seed in range(NUM_SEEDS):  # Repeat multiple times for reliability\n",
    "            print(f\"[D]\\t\\tseed: {seed}\", end=\"\\r\", flush=True)\n",
    "            X_sample, y_sample = create_random_sample(\n",
    "                x_train, y_train, sample_size, sub_sample_type, seed\n",
    "            )\n",
    "            \n",
    "            if X_sample.empty:\n",
    "                continue\n",
    "            # Train the model on the sampled data\n",
    "            clf = RandomForestRegressor(random_state=1, n_estimators=100, max_depth=10)\n",
    "            clf.fit(X_sample[FIP_FEATURE_SET], y_sample)\n",
    "\n",
    "            # Evaluate the model on the test set\n",
    "            y_pred = clf.predict(x_test[FIP_FEATURE_SET])\n",
    "            mape, mae, r2, pcc, scc = compute_metrics(\n",
    "                ground_truth=y_test,\n",
    "                preds=y_pred,\n",
    "                verbose=False,\n",
    "            )\n",
    "\n",
    "            mapes.append(mape)\n",
    "            maes.append(mae)\n",
    "            r2s.append(r2)\n",
    "            pccs.append(round(pcc*100, 3))\n",
    "            sccs.append(round(scc*100, 3))\n",
    "            \n",
    "        if len(pccs) == 0:\n",
    "            continue \n",
    "            \n",
    "        results[counter] = {\n",
    "            'sampling': 'uniform',\n",
    "            'sub_sample_type': sub_sample_type,\n",
    "            'sample_size': sample_size,\n",
    "            'train_size': len(X_sample),\n",
    "            'test_size': len(x_test),\n",
    "        }\n",
    "\n",
    "        for metric_name, metric in zip(['mape', 'mae', 'r2', 'pcc', 'scc'], [mapes, maes, r2s, pccs, sccs]):\n",
    "            results[counter][f'avg-{metric_name}'] = np.mean(metric)\n",
    "            results[counter][f'stdev-{metric_name}'] = np.std(metric)\n",
    "            results[counter][f'90th-{metric_name}'] = np.percentile(metric, 90)\n",
    "            results[counter][f'99th-{metric_name}'] = np.percentile(metric, 99)\n",
    "\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f4063",
   "metadata": {},
   "source": [
    "## Stratified random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c92c98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T20:37:38.473260Z",
     "start_time": "2024-07-23T20:37:38.473252Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the sample sizes you want to test\n",
    "# these are percentages of the train-set\n",
    "sample_sizes = [0.1, 1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 99]\n",
    "\n",
    "for sample_size in sample_sizes:\n",
    "    mapes = []\n",
    "    maes = []\n",
    "    r2s = []\n",
    "    pccs = []\n",
    "    sccs = []\n",
    "\n",
    "    # Binning the target variable into discrete categories\n",
    "    # For example, using 10 bins\n",
    "    num_bins = 10\n",
    "    y_binned = pd.cut(y_train, bins=num_bins, labels=False)\n",
    "\n",
    "    # Define the stratified splitter\n",
    "    # Here we use n_splits = NUM_SEEDS \n",
    "    # to create NUM_SEEDS different sub-samples\n",
    "    stratified_splitter = StratifiedShuffleSplit(\n",
    "        n_splits=NUM_SEEDS, \n",
    "        train_size=int((sample_size/100)*len(x_train)), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Create stratified sub-samples\n",
    "    for train_index, test_index in stratified_splitter.split(x_train, y_binned):\n",
    "        X_train_subsample = x_train.iloc[train_index]\n",
    "        y_train_subsample = y_train.iloc[train_index]\n",
    "#         X_test_subsample = x_test.iloc[test_index]\n",
    "#         y_test_subsample = y_test.iloc[test_index]\n",
    "\n",
    "        # Here, you can use the sub-sample (X_train_subsample, y_train_subsample)\n",
    "        # to train and evaluate your model\n",
    "        clf = RandomForestRegressor(random_state=1, n_estimators=100, max_depth=10)\n",
    "        clf.fit(X_train_subsample, y_train_subsample)\n",
    "        \n",
    "        # Evaluate the model on the test set\n",
    "        y_pred = clf.predict(x_test)\n",
    "        mape, mae, r2, pcc, scc = compute_metrics(\n",
    "            ground_truth=y_test,\n",
    "            preds=y_pred,\n",
    "            verbose=False,\n",
    "        )\n",
    "        \n",
    "        mapes.append(mape)\n",
    "        maes.append(mae)\n",
    "        r2s.append(r2)\n",
    "        pccs.append(round(pcc*100, 3))\n",
    "        sccs.append(round(scc*100, 3))\n",
    "        \n",
    "        boxplot_res_dict[len(results)*NUM_SEEDS + seed] = {\n",
    "            'seed': seed,\n",
    "            'sampling': 'uniform',\n",
    "            'sub_sample_type': sub_sample_type,\n",
    "            'sample_size': sample_size,\n",
    "            'train_size': len(X_sample),\n",
    "            'test_size': len(x_test),\n",
    "            'mape': mape,\n",
    "            'mae': mae,\n",
    "            'pcc': round(pcc*100, 5),                \n",
    "            'scc': round(scc*100, 5)\n",
    "        }\n",
    "    \n",
    "    results[counter] = {\n",
    "        'sampling': 'stratified',\n",
    "        'sample_size': sample_size,\n",
    "        'train_size': len(X_train_subsample),\n",
    "        'test_size': len(x_test),\n",
    "    }\n",
    "    \n",
    "    for metric_name, metric in zip(['mape', 'mae', 'r2', 'pcc', 'scc'], [mapes, maes, r2s, pccs, sccs]):\n",
    "        results[counter][f'avg-{metric_name}'] = np.mean(metric)\n",
    "        results[counter][f'stdev-{metric_name}'] = np.std(metric)\n",
    "        results[counter][f'90th-{metric_name}'] = np.percentile(metric, 90)\n",
    "        results[counter][f'99th-{metric_name}'] = np.percentile(metric, 99)\n",
    "        \n",
    "        \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de148a",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ea7730c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:32:47.357292Z",
     "start_time": "2024-07-29T20:32:47.352213Z"
    }
   },
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(results).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a4b45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:32:47.362651Z",
     "start_time": "2024-07-29T20:32:47.358868Z"
    }
   },
   "outputs": [],
   "source": [
    "list(res_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc4949b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:32:47.373467Z",
     "start_time": "2024-07-29T20:32:47.364324Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_df[[\n",
    "    'sampling',\n",
    "    'sub_sample_type',\n",
    "    'sample_size',\n",
    "    'train_size',\n",
    "    'test_size',\n",
    "    \n",
    "    'avg-mae',\n",
    "    'stdev-mae',\n",
    "    'avg-pcc',\n",
    "    'stdev-pcc',\n",
    "#     'avg-scc',\n",
    "#     'avg-r2',\n",
    "#     'avg-mape',\n",
    "    \n",
    "    '90th-mae',\n",
    "    '90th-pcc',\n",
    "#     '90th-scc',\n",
    "#     '90th-r2',\n",
    "#     '90th-mape',\n",
    "    \n",
    "#     '99th-mae',\n",
    "#     '99th-pcc',\n",
    "#     '99th-scc',\n",
    "#     '99th-r2',\n",
    "#     '99th-mape',\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12176b40",
   "metadata": {},
   "source": [
    "### Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69ecfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:32:47.377790Z",
     "start_time": "2024-07-29T20:32:47.374583Z"
    }
   },
   "outputs": [],
   "source": [
    "res_df.sample_size.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c3cab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T19:49:47.563502Z",
     "start_time": "2024-07-30T19:49:47.006683Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "COLS = [\n",
    "    'avg-mae',\n",
    "    'avg-pcc',\n",
    "    '90th-mae',\n",
    "    '90th-pcc',\n",
    "]\n",
    "\n",
    "SAMPLE_SIZES = [\n",
    "    5, 10, 30, 50, 70, 90, 100\n",
    "#     5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100\n",
    "]\n",
    "\n",
    "for x_col in COLS:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    \n",
    "    plot_data = res_df.loc[\n",
    "        res_df.sample_size.isin(SAMPLE_SIZES)\n",
    "    ].copy()\n",
    "        \n",
    "    sns_plot = sns.barplot(\n",
    "        data=plot_data,\n",
    "        x='sample_size',\n",
    "        y=x_col,\n",
    "        hue='sub_sample_type',\n",
    "        ax=ax,\n",
    "#         hue_order=targets,\n",
    "        palette=sns.color_palette(\n",
    "            palette='gist_heat', \n",
    "            n_colors=len(plot_data.sub_sample_type.unique())\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    if 'avg' in x_col:\n",
    "        \n",
    "        # Add error bars\n",
    "        num_hue_levels = len(plot_data.sub_sample_type.unique())\n",
    "        num_categories = len(plot_data.sample_size.unique())\n",
    "\n",
    "        for i, patch in enumerate(ax.patches):\n",
    "            # Determine the index of the category and hue\n",
    "            category_index = i // num_hue_levels\n",
    "            hue_index = i % num_hue_levels\n",
    "\n",
    "            # Calculate the center of each bar\n",
    "            bar_center = patch.get_x() + patch.get_width() / 2\n",
    "\n",
    "            # Get the corresponding error value\n",
    "            error = plot_data[f\"stdev-{x_col.split('-')[1]}\"].iloc[category_index * num_hue_levels + hue_index]\n",
    "\n",
    "            # Add error bars\n",
    "            ax.errorbar(\n",
    "                bar_center, \n",
    "                patch.get_height(), \n",
    "                yerr=error, \n",
    "                fmt='none', \n",
    "                c='black', \n",
    "                capsize=5\n",
    "            )\n",
    "\n",
    "    ax.set_ylabel(x_col.capitalize().replace(\"-\", \" \"))\n",
    "    ax.set_xlabel(\"Sample size\")\n",
    "#         ax.set_yscale('log')\n",
    "\n",
    "\n",
    "    ax.legend(\n",
    "#         loc='upper right', \n",
    "#         bbox_to_anchor=(1.0, 1.35),\n",
    "#         ncol=3,\n",
    "        title='Sub-sample type',\n",
    "        frameon=False,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef5824d",
   "metadata": {},
   "source": [
    "### Box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb9eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_res = pd.DataFrame(boxplot_res_dict).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bd0bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_res.loc[\n",
    "    (boxplot_res.sample_size == 100)\n",
    "    #& (boxplot_res.sub_sample_type == 'features')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c1f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZES = [\n",
    "    5, 10, 30, 50, 70, 90, 100\n",
    "#     5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100\n",
    "]\n",
    "\n",
    "for y_col in ['pcc', 'mae', 'mape', 'scc']:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    \n",
    "    plot_data = boxplot_res.loc[\n",
    "        boxplot_res.sample_size.isin(SAMPLE_SIZES)\n",
    "    ].copy()\n",
    "        \n",
    "    sns.boxplot(\n",
    "        data=plot_data, \n",
    "        x=\"sample_size\", \n",
    "        y=y_col, \n",
    "        hue=\"sub_sample_type\",\n",
    "        ax=ax,\n",
    "        palette=sns.color_palette(\n",
    "            palette='gist_heat', \n",
    "            n_colors=len(plot_data.sub_sample_type.unique())\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    ax.set_ylabel(y_col.upper())\n",
    "    ax.set_xlabel(\"Sample size\")\n",
    "\n",
    "    ax.legend(\n",
    "        title='Sub-sample type',\n",
    "        frameon=False,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env-amt]",
   "language": "python",
   "name": "conda-env-env-amt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "247.43px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
